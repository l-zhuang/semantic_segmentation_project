{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "import torch.utils.data as data\n",
    "from . import utils\n",
    "\n",
    "\n",
    "class Cityscapes(data.Dataset):\n",
    "    \"\"\"Cityscapes dataset https://www.cityscapes-dataset.com/.\n",
    "\n",
    "    Keyword arguments:\n",
    "    - root_dir (``string``): Root directory path.\n",
    "    - mode (``string``): The type of dataset: 'train' for training set, 'val'\n",
    "    for validation set, and 'test' for test set.\n",
    "    - transform (``callable``, optional): A function/transform that  takes in\n",
    "    an PIL image and returns a transformed version. Default: None.\n",
    "    - label_transform (``callable``, optional): A function/transform that takes\n",
    "    in the target and transforms it. Default: None.\n",
    "    - loader (``callable``, optional): A function to load an image given its\n",
    "    path. By default ``default_loader`` is used.\n",
    "\n",
    "    \"\"\"\n",
    "    # Training dataset root folders\n",
    "    train_folder = \"leftImg8bit_trainvaltest/leftImg8bit/train\"\n",
    "    train_lbl_folder = \"gtFine_trainvaltest/gtFine/train\"\n",
    "\n",
    "    # Validation dataset root folders\n",
    "    val_folder = \"leftImg8bit_trainvaltest/leftImg8bit/val\"\n",
    "    val_lbl_folder = \"gtFine_trainvaltest/gtFine/val\"\n",
    "\n",
    "    # Test dataset root folders\n",
    "    test_folder = \"leftImg8bit_trainvaltest/leftImg8bit/test\"\n",
    "    test_lbl_folder = \"gtFine_trainvaltest/gtFine/test\"\n",
    "\n",
    "    # Filters to find the images\n",
    "    img_extension = '.png'\n",
    "    lbl_name_filter = 'labelIds'\n",
    "\n",
    "    # The values associated with the 35 classes\n",
    "    full_classes = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
    "                    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
    "                    32, 33, -1)\n",
    "    # The values above are remapped to the following\n",
    "    new_classes = (0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 3, 4, 5, 0, 0, 0, 6, 0, 7,\n",
    "                   8, 9, 10, 11, 12, 13, 14, 15, 16, 0, 0, 17, 18, 19, 0)\n",
    "\n",
    "    # Default encoding for pixel value, class name, and class color\n",
    "    color_encoding = OrderedDict([\n",
    "            ('unlabeled', (0, 0, 0)),\n",
    "            ('road', (128, 64, 128)),\n",
    "            ('sidewalk', (244, 35, 232)),\n",
    "            ('building', (70, 70, 70)),\n",
    "            ('wall', (102, 102, 156)),\n",
    "            ('fence', (190, 153, 153)),\n",
    "            ('pole', (153, 153, 153)),\n",
    "            ('traffic_light', (250, 170, 30)),\n",
    "            ('traffic_sign', (220, 220, 0)),\n",
    "            ('vegetation', (107, 142, 35)),\n",
    "            ('terrain', (152, 251, 152)),\n",
    "            ('sky', (70, 130, 180)),\n",
    "            ('person', (220, 20, 60)),\n",
    "            ('rider', (255, 0, 0)),\n",
    "            ('car', (0, 0, 142)),\n",
    "            ('truck', (0, 0, 70)),\n",
    "            ('bus', (0, 60, 100)),\n",
    "            ('train', (0, 80, 100)),\n",
    "            ('motorcycle', (0, 0, 230)),\n",
    "            ('bicycle', (119, 11, 32))\n",
    "    ])\n",
    "\n",
    "    def __init__(self,\n",
    "                 root_dir,\n",
    "                 mode='train',\n",
    "                 transform=None,\n",
    "                 label_transform=None,\n",
    "                 loader=utils.pil_loader):\n",
    "        self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.label_transform = label_transform\n",
    "        self.loader = loader\n",
    "\n",
    "        if self.mode.lower() == 'train':\n",
    "            # Get the training data and labels filepaths\n",
    "            self.train_data = utils.get_files(\n",
    "                os.path.join(root_dir, self.train_folder),\n",
    "                extension_filter=self.img_extension)\n",
    "\n",
    "            self.train_labels = utils.get_files(\n",
    "                os.path.join(root_dir, self.train_lbl_folder),\n",
    "                name_filter=self.lbl_name_filter,\n",
    "                extension_filter=self.img_extension)\n",
    "        elif self.mode.lower() == 'val':\n",
    "            # Get the validation data and labels filepaths\n",
    "            self.val_data = utils.get_files(\n",
    "                os.path.join(root_dir, self.val_folder),\n",
    "                extension_filter=self.img_extension)\n",
    "\n",
    "            self.val_labels = utils.get_files(\n",
    "                os.path.join(root_dir, self.val_lbl_folder),\n",
    "                name_filter=self.lbl_name_filter,\n",
    "                extension_filter=self.img_extension)\n",
    "        elif self.mode.lower() == 'test':\n",
    "            # Get the test data and labels filepaths\n",
    "            self.test_data = utils.get_files(\n",
    "                os.path.join(root_dir, self.test_folder),\n",
    "                extension_filter=self.img_extension)\n",
    "\n",
    "            self.test_labels = utils.get_files(\n",
    "                os.path.join(root_dir, self.test_lbl_folder),\n",
    "                name_filter=self.lbl_name_filter,\n",
    "                extension_filter=self.img_extension)\n",
    "        else:\n",
    "            raise RuntimeError(\"Unexpected dataset mode. \"\n",
    "                               \"Supported modes are: train, val and test\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - index (``int``): index of the item in the dataset\n",
    "\n",
    "        Returns:\n",
    "        A tuple of ``PIL.Image`` (image, label) where label is the ground-truth\n",
    "        of the image.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.mode.lower() == 'train':\n",
    "            data_path, label_path = self.train_data[index], self.train_labels[\n",
    "                index]\n",
    "        elif self.mode.lower() == 'val':\n",
    "            data_path, label_path = self.val_data[index], self.val_labels[\n",
    "                index]\n",
    "        elif self.mode.lower() == 'test':\n",
    "            data_path, label_path = self.test_data[index], self.test_labels[\n",
    "                index]\n",
    "        else:\n",
    "            raise RuntimeError(\"Unexpected dataset mode. \"\n",
    "                               \"Supported modes are: train, val and test\")\n",
    "\n",
    "        img, label = self.loader(data_path, label_path)\n",
    "\n",
    "        # Remap class labels\n",
    "        label = utils.remap(label, self.full_classes, self.new_classes)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.label_transform is not None:\n",
    "            label = self.label_transform(label)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the dataset.\"\"\"\n",
    "        if self.mode.lower() == 'train':\n",
    "            return len(self.train_data)\n",
    "        elif self.mode.lower() == 'val':\n",
    "            return len(self.val_data)\n",
    "        elif self.mode.lower() == 'test':\n",
    "            return len(self.test_data)\n",
    "        else:\n",
    "            raise RuntimeError(\"Unexpected dataset mode. \"\n",
    "                               \"Supported modes are: train, val and test\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
